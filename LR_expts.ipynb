{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "#load theta matrix, dt vector associated with Diffusion Equation with Diffusion Term only\n",
    "theta_path = '/mnt/mbi/home/e0031794/Documents/FYP/FYP_results_11_9_2019/data_slicing_val_diff_10_1/1_trial/500_subset_clean/Out_subset_500_Original DeepMod/20200220_110440/theta.npy'\n",
    "\n",
    "theta = np.load(theta_path)\n",
    "\n",
    "dt_path = '/mnt/mbi/home/e0031794/Documents/FYP/FYP_results_11_9_2019/data_slicing_val_diff_10_1/1_trial/500_subset_clean/Out_subset_500_Original DeepMod/20200220_110440/time_deriv.npy'\n",
    "\n",
    "dt = np.load(dt_path)[0]\n",
    "#deepmod: fit first, then normalise theta/dt and epsilon to generate bit mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Normalisation and consequences demo\n",
      "Normalisation for LR\n",
      "Coeffs:  [[ 0.         -0.83730394  8.745507   14.349687   -0.07737297 -1.692133\n",
      "   0.9870669   5.4431195   0.02038591  0.8381659  -0.07162718  1.537311  ]]\n",
      "sparse_pattern:  [[False False  True  True False False False  True False False False False]]\n",
      "\n",
      "No Normalisation for LR\n",
      "Coeffs:  [[ 0.         -0.837323    8.745499   14.349821   -0.07737497 -1.6921293\n",
      "   0.9870912   5.44313     0.02038723  0.8381655  -0.0716278   1.5373114 ]]\n",
      "sparse_pattern:  [[False False  True  True False False False  True False False False False]]\n",
      "\n",
      "Notice 3rd coefficient, which corresponds to diffusion coefficient is an invariant,\n",
      "for ordinary least squares, irregardless of normalisation\n"
     ]
    }
   ],
   "source": [
    "#vanilla LR on theta, dt from above\n",
    "print('Weight Normalisation and consequences demo')\n",
    "print('Normalisation for LR')\n",
    "norm_lr = LinearRegression(normalize=True).fit(theta, dt) #creates LR model\n",
    "\n",
    "print('Coeffs: ', str(norm_lr.coef_))\n",
    "norm_coeff = norm_lr.coef_\n",
    "upper_lim, lower_lim = np.median(norm_coeff) + np.std(norm_coeff), np.median(norm_coeff) - np.std(norm_coeff)\n",
    "sparsity_mask_lr = (norm_coeff <= upper_lim) & (norm_coeff >= lower_lim)\n",
    "print('sparse_pattern: ', str(~sparsity_mask_lr) + '\\n')\n",
    "\n",
    "print('No Normalisation for LR')\n",
    "lr = LinearRegression(normalize=False).fit(theta, dt) #creates LR model\n",
    "\n",
    "print('Coeffs: ', str(lr.coef_))\n",
    "LR_coeff = lr.coef_\n",
    "upper_lim, lower_lim = np.median(LR_coeff) + np.std(LR_coeff), np.median(LR_coeff) - np.std(LR_coeff)\n",
    "sparsity_mask_lr = (LR_coeff <= upper_lim) & (LR_coeff >= lower_lim)\n",
    "print('sparse_pattern: ', str(~sparsity_mask_lr) + '\\n')\n",
    "\n",
    "print('Notice 3rd coefficient, which corresponds to diffusion coefficient is an invariant,')\n",
    "print('for ordinary least squares, irregardless of normalisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation for Lasso LR\n",
      "Coeffs:  [[ 0.00000000e+00 -8.78933012e-01  8.97778225e+00  1.24961405e+01\n",
      "  -8.45130086e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.52698979e-01 -2.59345165e-04  3.88002872e-01]]\n",
      "sparse_pattern:  [[False False  True  True False False False False False False False False]]\n",
      "\n",
      "No Normalisation for Lasso LR\n",
      "Coeffs [[ 0.         -0.80563444  8.722532   14.137315   -0.08469176 -1.698046\n",
      "   0.9861577   5.418448    0.02130774  0.83511597 -0.07094496  1.5308359 ]]\n",
      "sparse_pattern:  [[False False  True  True False False False  True False False False False]]\n",
      "\n",
      "Notice 3rd coefficient, which corresponds to diffusion coefficient is not an invariant,\n",
      "with and without normalisation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.022727966308594, tolerance: 0.09935914725065231\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "#Lasso LR on theta, dt from above\n",
    "print('Normalisation for Lasso LR')\n",
    "norm_L1_lr = linear_model.Lasso(alpha=1e-05, normalize=True, max_iter=50000, tol=1e-06).fit(theta, dt)\n",
    "\n",
    "#normalise: substract mean, divided by L2 norm, we normalise then we fit L1 regression\n",
    "print('Coeffs: ', str(norm_L1_lr.sparse_coef_.toarray()))\n",
    "norm_L1_coeff = norm_L1_lr.sparse_coef_.toarray()\n",
    "upper_lim, lower_lim = np.median(norm_L1_coeff ) + np.std(norm_L1_coeff ), np.median(norm_L1_coeff ) - np.std(norm_L1_coeff )\n",
    "sparsity_mask_l1 = (norm_L1_coeff  <= upper_lim) & (norm_L1_coeff  >= lower_lim)\n",
    "print('sparse_pattern: ', str(~sparsity_mask_l1) + '\\n')\n",
    "\n",
    "print('No Normalisation for Lasso LR')\n",
    "L1_lr = linear_model.Lasso(alpha=1e-05, normalize=False, max_iter=50000, tol=1e-06).fit(theta, dt)\n",
    "\n",
    "#normalise: substract mean, divided by L2 norm, we normalise then we fit L1 regression\n",
    "print('Coeffs', str(L1_lr.sparse_coef_.toarray()))\n",
    "L1_coeff = L1_lr.sparse_coef_.toarray()\n",
    "upper_lim, lower_lim = np.median(L1_coeff) + np.std(L1_coeff), np.median(L1_coeff) - np.std(L1_coeff)\n",
    "sparsity_mask_l1 = (L1_coeff <= upper_lim) & (L1_coeff >= lower_lim)\n",
    "\n",
    "print('sparse_pattern: ', str(~sparsity_mask_l1) + '\\n')\n",
    "\n",
    "print('Notice 3rd coefficient, which corresponds to diffusion coefficient is not an invariant,')\n",
    "print('with and without normalisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, compare the sparse pattern obtained from Deepmod, with the above\n",
      "sparse_pattern from deepmod:  [[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "print('Now, compare the sparse pattern obtained from Deepmod, with the above')\n",
    "sparse_pattern_from_deepmod = np.load('/mnt/mbi/home/e0031794/Documents/FYP/FYP_results_11_9_2019/data_slicing_val_diff_10_1/1_trial/500_subset_clean/google_drive_storage_Original DeepMod/sparse_pattern_500.npy')\n",
    "print('sparse_pattern from deepmod: ', sparse_pattern_from_deepmod[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR coeff [[9.679331  4.0417533]]\n",
      "L1 coeff [[9.623247 3.921462]]\n"
     ]
    }
   ],
   "source": [
    "#refitting with LR and L1 LR. select 3rd, 4th columns of theta matrix based on sparse pattern generated from\n",
    "#L1 regression\n",
    "#This section simulates the refitting procedure of Deepmod\n",
    "#L1 and Ordinary Least squares regressions are used for comparison purposes.\n",
    "reduced_theta = theta[:, [2,3]]\n",
    "\n",
    "#vanilla LR\n",
    "lr = LinearRegression().fit(reduced_theta, dt) #creates LR model\n",
    "print('LR coeff', lr.coef_)\n",
    "\n",
    "#L1 regression\n",
    "L1_lr = linear_model.Lasso(alpha=1e-05, normalize=True, max_iter=50000, tol=1e-06).fit(reduced_theta, dt)\n",
    "print('L1 coeff', L1_lr.sparse_coef_.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}